{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af81bf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5befb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\n"
     ]
    }
   ],
   "source": [
    "print(chr(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86ab8392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\x00'\n"
     ]
    }
   ],
   "source": [
    "print(chr(0).__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2713675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"this is a test\" + chr(0) + \"string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0427ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a test\u0000string\n"
     ]
    }
   ],
   "source": [
    "print(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f23957",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"hello! こんにちは!\"\n",
    "utf8_encoded = test_string.encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dfe39e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello! \\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf!'\n",
      "[104, 101, 108, 108, 111, 33, 32, 227, 129, 147, 227, 130, 147, 227, 129, 171, 227, 129, 161, 227, 129, 175, 33]\n"
     ]
    }
   ],
   "source": [
    "print(utf8_encoded)\n",
    "print(list(utf8_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7458edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 23)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_string), len(utf8_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36c8a6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello! こんにちは!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utf8_encoded.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19c060d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "utf16_encoded = test_string.encode(\"utf-16\")\n",
    "utf32_encoded = test_string.encode(\"utf-32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e16e754b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "28\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "print (len(list(utf8_encoded)))\n",
    "print (len(list(utf16_encoded)))\n",
    "print (len(list(utf32_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4eefcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "test_string = \"hello\"\n",
    "print(len(test_string))\n",
    "print(len(list(test_string.encode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0575596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_utf8_bytes_to_str_wrong(bytestring: bytes):\n",
    "\treturn \"\".join([bytes([b]).decode(\"utf-8\") for b in bytestring])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5434aacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_utf8_bytes_to_str_wrong(\"hello\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8be6498b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[104, 101, 108, 108, 111]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\"hello\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17c3284",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe3 in position 0: unexpected end of data",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdecode_utf8_bytes_to_str_wrong\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhello! こんにちは!\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Error\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mdecode_utf8_bytes_to_str_wrong\u001b[39m\u001b[34m(bytestring)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_utf8_bytes_to_str_wrong\u001b[39m(bytestring: \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bytestring])\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xe3 in position 0: unexpected end of data"
     ]
    }
   ],
   "source": [
    "# decode_utf8_bytes_to_str_wrong(\"hello! こんにちは!\".encode(\"utf-8\")) # Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ae681b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode bytes in position 0-1: unexpected end of data",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mこ\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Error - probably no byte sequence can be prefix of any other?\u001b[39;00m\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode bytes in position 0-1: unexpected end of data"
     ]
    }
   ],
   "source": [
    "bytes(list(\"こ\".encode(\"utf-8\"))[:-1]).decode(\"utf-8\") # Error - probably no byte sequence can be prefix of any other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b6f0175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c281e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e34fd9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['some', ' text', ' that', ' i', \"'ll\", ' pre', '-', 'tokenize']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(PAT, \"some text that i'll pre-tokenize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5205bac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', ' is', ' a', ' piece', ' of', ' random', ' text']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(PAT, \"this is a piece of random text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55c57060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', ' is', ' a', ' piece', ' of', ' random', ' text', '.']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(PAT, \"this is a piece of random text.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb8619",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "with open('tiny_corpus.txt', 'r') as f:\n",
    "\tfor line in f.readlines():\n",
    "\t\tcorpus.extend([word.strip() for word in line.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5c6dbd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def bpe_tokenizer(corpus, num_merges):\n",
    "\tnew_tokens = []\n",
    "\n",
    "\t# Create a dict mapping pretokens to frequency\n",
    "\tfreq = Counter()\n",
    "\n",
    "\tfor pretoken in corpus:\n",
    "\t\tfreq[tuple(pretoken)] += 1\n",
    "\n",
    "\t# Loop through for num_merges\n",
    "\tfor _ in range(num_merges):\n",
    "\n",
    "\t\t# Count the number of co-orccurences\n",
    "\t\tbigrams = Counter()\n",
    "\n",
    "\t\tfor pretoken in freq.keys():\n",
    "\t\t\tfor char_1, char_2 in zip(pretoken[:-1], pretoken[1:]):\n",
    "\t\t\t\tbigrams[(char_1, char_2)] += freq[pretoken]\n",
    "\n",
    "\t\t# Get the max one resolving ties lexicographically\n",
    "\t\tmax_val = max(bigrams.values())\n",
    "\t\tmax_bigrams = [bigram for bigram in bigrams if bigrams[bigram] == max_val ]\n",
    "\n",
    "\t\t# Append to new_tokens\n",
    "\t\tmerge_rule = max(max_bigrams)\n",
    "\t\tnew_tokens.append(''.join(merge_rule))\n",
    "\n",
    "\t\t# Create new dict mapping pretokens to frequency with merge\n",
    "\t\tnew_freq = {}\n",
    "\t\tfor pretoken, val in freq.items():\n",
    "\t\t\ti = 0\n",
    "\t\t\tnew_pretoken = []\n",
    "\t\t\twhile i < len(pretoken) - 1:\n",
    "\t\t\t\tchar_1 = pretoken[i]\n",
    "\t\t\t\tchar_2 = pretoken[i + 1]\n",
    "\n",
    "\t\t\t\tif char_1 == merge_rule[0] and char_2 == merge_rule[1]:\n",
    "\t\t\t\t\tnew_pretoken.append(char_1 + char_2)\n",
    "\t\t\t\t\ti += 2\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tnew_pretoken.append(char_1)\n",
    "\t\t\t\t\ti += 1\n",
    "\n",
    "\t\t\tif i == len(pretoken) - 1:\n",
    "\t\t\t\tnew_pretoken.append(pretoken[i])\n",
    "\t\t\tnew_freq[tuple(new_pretoken)] = val\n",
    "\t\t\n",
    "\t\t# Replace existing mapping\n",
    "\t\tfreq = new_freq\n",
    "\treturn new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a73ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['st', 'est', 'ow', 'low', 'west', 'ne']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_tokenizer(corpus, 6)\n",
    "\n",
    "# Making an assumption here that each character is mapping to 1 byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "170eb95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/TinyStoriesV2-GPT4-train.txt', 'r') as f:\n",
    "\tlines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd62a17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b0ca78",
   "metadata": {},
   "source": [
    "#### GRAVEYARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "177b0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs336_basics.pretokenization_example import find_chunk_boundaries\n",
    "f = open('data/TinyStoriesV2-GPT4-train.txt', 'rb')\n",
    "desired_num_chunks = 100\n",
    "split_special_token = b'<|endoftext|>'\n",
    "chunk_boundaries = find_chunk_boundaries(f, desired_num_chunks, split_special_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b48fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "f.seek(chunk_boundaries[i])\n",
    "op = f.read(chunk_boundaries[i + 1] - chunk_boundaries[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b612e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_str = op.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5223c2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d her mom went to the store and picked out the most beautiful kite they could find. It was red, blue, and yellow. Lily was so grateful to her mom for helping her get the kite. They went to the park to fly the kite together.\n",
      "At the park, Lily and her mom ran and laughed as they flew the kite high in the sky. The kite danced in the wind, and Lily's dream had come true. She was so grateful for her mom and the fun day they had together.\n",
      "From that day on, Lily and her mom flew the kite at the park whenever they could. They had so much fun together, and Lily knew that dreams can come true. She was very grateful for her mom and her pretty, colorful kite.\n",
      "<|endoftext|>\n",
      "Once upon a time, there was a pretty landscape with many trees. It was a happy place. One day, a big wind came and blew very hard. It made the trees bend and shake. The animals in the landscape were scared.\n",
      "A little bird had a nest in one of the trees. The bird's nest started to hang on a branch, about to fall. The little bird was very sad and did not know what to do. The other animals saw the little bird and wanted to help.\n",
      "The animals worked together to make the nest safe. They pushed and pulled the branch until the nest was not hanging anymore. The little bird was so happy and thanked the animals. They all learned that when things are hard, friends can help make it better. And they lived happily in the pretty landscape.\n",
      "<|endoftext|>\n",
      "\n",
      "One day, two brothers were playing. The older brother was eager to show his little brother something fun. He let his brother climb onto his back and they ran outside. They went to the park, where the older brother let his brother slide down the slide. His brother was so eager to ride the slide again that he went back up the stairs and slid down again. After a few runs, the older brother let his brother go on the swings. He swung back and forth, giggling with delight. The brothers had a great time together and the older brother was happy to let his brother try out new things.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(op_str[-2000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db636c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw many amazing things, like beautiful vases that were on display in a store. One day, Ben was walking through the store when he came across a very special vase. When Ben saw it he was amazed!  \n",
      "He said, “Wow, that is a really amazing vase! Can I buy it?” \n",
      "The shopkeeper smiled and said, “Of course you can. You can take it home and show all your friends how amazing it is!”\n",
      "So Ben took the vase home and he was so proud of it! He called his friends over and showed them the amazing vase. All his friends thought the vase was beautiful and couldn't believe how lucky Ben was. \n",
      "And that's how Ben found an amazing vase in the store!\n",
      "<|endoftext|>\n",
      "Once upon a time, there was a reliable otter named Ollie. He lived in a river with his family. They all loved to play and swim together.\n",
      "One day, Ollie's mom said, \"Ollie, hurry and get some fish for dinner!\" Ollie swam fast to catch fish. He saw his fri\n"
     ]
    }
   ],
   "source": [
    "print(op_str[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "035e6085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_special_token.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e56e00da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import multiprocessing as mp\n",
    "from collections import Counter\n",
    "from cs336_basics.pretokenization_example import find_chunk_boundaries\n",
    "\n",
    "file = open('data/TinyStoriesV2-GPT4-train.txt', 'rb')\n",
    "desired_num_chunks = 100\n",
    "split_special_token = b'<|endoftext|>'\n",
    "special_tokens = [split_special_token]\n",
    "\n",
    "chunk_boundaries = find_chunk_boundaries(file, desired_num_chunks, split_special_token)\n",
    "chunks = []\n",
    "\n",
    "for idx in range(len(chunk_boundaries) - 1):\n",
    "\tfile.seek(chunk_boundaries[idx])\n",
    "\tchunks.append(file.read(chunk_boundaries[idx + 1] - chunk_boundaries[idx]))\n",
    "\n",
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "\n",
    "def process_each_chunk(chunk: bytes, special_tokens: list[bytes])-> Counter:\n",
    "\t# Remove special tokens\n",
    "\tpattern = b'|'.join(re.escape(tok) for tok in special_tokens)\n",
    "\tchunk_no_special_tokens = b\" \".join(re.split(pattern, chunk))\n",
    "\tcounter = Counter()\n",
    "\n",
    "\tfor pretoken in re.finditer(PAT, chunk_no_special_tokens.decode(\"utf-8\")):\n",
    "\t\tpretoken = pretoken.group()\n",
    "\t\tpretoken = tuple(pretoken.encode(\"utf-8\"))\n",
    "\t\tcounter[tuple(pretoken)] += 1\n",
    "\n",
    "\treturn counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4585dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run above function on each chunk\n",
    "with mp.Pool() as pool:\n",
    "\tlocal_counters = pool.starmap(\n",
    "\t\tprocess_each_chunk,\n",
    "\t\t[(chunk, special_tokens) for chunk in chunks[:20]]\n",
    "\t)\n",
    "\n",
    "# Merge all local counters\n",
    "final_counter = Counter()\n",
    "for counter in local_counters:\n",
    "\tfinal_counter.update(counter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
